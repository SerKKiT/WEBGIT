package kafka

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"time"

	"github.com/segmentio/kafka-go"
)

type Producer struct {
	writer *kafka.Writer
}

type RecordingTask struct {
	StreamID     string    `json:"stream_id"`
	UserID       int       `json:"user_id"`  // ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û
	Username     string    `json:"username"` // ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û
	Title        string    `json:"title"`
	Action       string    `json:"action"`   // "stop_recording", "start_recording"
	HLSPath      string    `json:"hls_path"` // –ø—É—Ç—å –∫ HLS —Å–µ–≥–º–µ–Ω—Ç–∞–º
	StartTime    time.Time `json:"start_time"`
	EndTime      time.Time `json:"end_time"`
	Duration     int       `json:"duration_seconds"`
	FileSize     int64     `json:"file_size_bytes,omitempty"`
	SegmentCount int       `json:"segment_count,omitempty"`
	Status       string    `json:"status"` // "completed", "failed"
	Timestamp    time.Time `json:"timestamp"`
	ErrorMsg     string    `json:"error_message,omitempty"`
}

// –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π producer
func NewProducer() (*Producer, error) {
	brokers := os.Getenv("KAFKA_BROKERS")
	if brokers == "" {
		brokers = "kafka:29092"
	}

	log.Printf("üîó Connecting to Kafka brokers: %s", brokers)

	writer := &kafka.Writer{
		Addr:                   kafka.TCP(brokers),
		Topic:                  "recording.tasks",
		Balancer:               &kafka.LeastBytes{},
		RequiredAcks:           kafka.RequireOne,
		Async:                  false, // –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏
		WriteTimeout:           10 * time.Second,
		ReadTimeout:            10 * time.Second,
		AllowAutoTopicCreation: true,
	}

	return &Producer{writer: writer}, nil
}

// –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–¥–∞—á—É –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø–∏—Å–∏
func (p *Producer) SendRecordingTask(ctx context.Context, task RecordingTask) error {
	// –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å timestamp –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω
	if task.Timestamp.IsZero() {
		task.Timestamp = time.Now()
	}

	// –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
	if task.StreamID == "" {
		return fmt.Errorf("stream_id is required")
	}
	if task.Action == "" {
		return fmt.Errorf("action is required")
	}

	// ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
	if task.UserID > 0 {
		log.Printf("üì® Sending recording task for authorized stream: %s (user: %s, id: %d)",
			task.StreamID, task.Username, task.UserID)
	} else {
		log.Printf("üì® Sending recording task for legacy stream: %s", task.StreamID)
	}

	// –°–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤ JSON
	taskBytes, err := json.Marshal(task)
	if err != nil {
		return fmt.Errorf("failed to marshal task: %w", err)
	}

	// –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
	message := kafka.Message{
		Key:   []byte(task.StreamID), // –ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ StreamID
		Value: taskBytes,
		Time:  task.Timestamp,
		Headers: []kafka.Header{
			{Key: "action", Value: []byte(task.Action)},
			{Key: "source", Value: []byte("stream-app")},
			{Key: "user_id", Value: []byte(fmt.Sprintf("%d", task.UserID))}, // ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û
		},
	}

	err = p.writer.WriteMessages(ctx, message)
	if err != nil {
		log.Printf("‚ùå Failed to send recording task for stream %s: %v", task.StreamID, err)
		return fmt.Errorf("failed to write to kafka: %w", err)
	}

	log.Printf("‚úÖ Recording task sent: stream=%s, user=%s(%d), action=%s, duration=%ds",
		task.StreamID, task.Username, task.UserID, task.Action, task.Duration)
	return nil
}

// –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–±—ã—Ç–∏–µ –æ —Å—Ç–∞—Ç—É—Å–µ
func (p *Producer) SendStatusEvent(ctx context.Context, streamID, status, message string) error {
	event := map[string]interface{}{
		"stream_id": streamID,
		"status":    status,
		"message":   message,
		"timestamp": time.Now(),
		"source":    "stream-app",
	}

	eventBytes, err := json.Marshal(event)
	if err != nil {
		return err
	}

	// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ç–æ–ø–∏–∫ events
	writer := &kafka.Writer{
		Addr:                   p.writer.Addr,
		Topic:                  "recording.events",
		Balancer:               &kafka.LeastBytes{},
		AllowAutoTopicCreation: true,
	}
	defer writer.Close()

	return writer.WriteMessages(ctx, kafka.Message{
		Key:   []byte(streamID),
		Value: eventBytes,
		Time:  time.Now(),
	})
}

// –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Kafka
func (p *Producer) TestConnection(ctx context.Context) error {
	testMessage := kafka.Message{
		Key:   []byte("health-check"),
		Value: []byte(`{"type":"health-check","timestamp":"` + time.Now().Format(time.RFC3339) + `"}`),
	}

	return p.writer.WriteMessages(ctx, testMessage)
}

// –ó–∞–∫—Ä—ã—Ç—å producer
func (p *Producer) Close() error {
	if p.writer != nil {
		return p.writer.Close()
	}
	return nil
}
